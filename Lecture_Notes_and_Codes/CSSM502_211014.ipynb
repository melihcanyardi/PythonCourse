{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b9bf48",
   "metadata": {},
   "source": [
    "# _p_-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293b01fe",
   "metadata": {},
   "source": [
    "## The definition of a _p_-Value\n",
    "\n",
    "- The probability of observing the data or data more extreme given the null hypothesis is true\n",
    "- The **null hypothesis** ($H_0$) is generally that there is no relationship (correlation) between two variables\n",
    "    - Examples of a null: There is no relationship between civil war onset and ethnic fractionalization\n",
    "- The **alternative hypothesis** ($H_1$): There exists a relationship\n",
    "- _p_-value is used to determine the \"significance\" of the relationship\n",
    "- The smaller the _p_-value, the less likely the data comes from the **null distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5201ae4c",
   "metadata": {},
   "source": [
    "## Probabilistic Modus Tollens (Denying the Consequent)\n",
    "\n",
    "- If A then B — If $H_0$ is true then the data will follow an expected pattern\n",
    "- Not B observed — The data do not follow the expected pattern\n",
    "- Therefore not A — Therefore $H_0$ is false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda65c8",
   "metadata": {},
   "source": [
    "- If A then b is highly unlikely — If $H_0$ is true then the data are highly likely to follow an expected pattern\n",
    "- Not B observed — The person is a member of Congress\n",
    "- Therefore A is highly unlikely — Therefore it is highly unlikely she is an American"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1676b097",
   "metadata": {},
   "source": [
    "- If A then B is highly unlikely — If a person is an American then it is highly unlikely she is a member of Congress\n",
    "- Not B observed — The person is a member of Congress\n",
    "- Therefore A is highly unlikely — Therefore it is unlikely she is an American"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de118e8",
   "metadata": {},
   "source": [
    "## The Inverse Probability Problem\n",
    "\n",
    "- **Common belief**: The smaller the _p_-value, the greater the probability that the null hypothesis is false\n",
    "- Incorrect interpretation is that null hypothesis significance test produces $p(H_0|D)$\n",
    "- Instead, produces $p(D|H_0)$\n",
    "- $p(H_0|D) = \\frac{p(H_0)}{p(D)}p(D|H_0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377ad1c",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "- Assume that 2% of the US population are members of some right-wing militia group $(p(M) = 0.002)$\n",
    "- A survey is 95% accurate on positive classification $(p(C|M) = 0.95)$ and 97% accurate on negative classification $(p(C^C|M^C) = 0.97)$\n",
    "- Therefore, $p(M|C) = \\frac{p(M)}{p(C)}p(C|M) = 0.38$\n",
    "- Probability of correctly classifying an individual as militia member given they are member is 0.95, yet the probability that a person is a militia member given a positive classification is 0.38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab033ae",
   "metadata": {},
   "source": [
    "## Significance Through Sample Size\n",
    "\n",
    "- Many have observed that a null hypothesis significance test based on a large sample size almost always results in **statistical significance**\n",
    "- Statistical significance in a large sample study does not imply real world importance\n",
    "- Researchers studying small sample events face substantial prejudice against their empirical findings when **alpha levels** appropriate to large sample research are applied\n",
    "- As sample size increases we are able to distinguish smaller population-effect sizes progressively\n",
    "- Interested in magnitude of effect; making binary decisions about the existence of an effect is not particularly informative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46682236",
   "metadata": {},
   "source": [
    "## Further Issues\n",
    "- Arbitrariness of **alpha**: \"... surely God loves .06 nearly as much as .05\" (Rosnow and Rosenthal 1989)\n",
    "- **Replication fallacy**: Probabilty of replication given a false null is actually the power of the test, not one minus alpha\n",
    "- Asymmetry and accepting the null hypothesis: $H_1$ is held innocent until proven guilty, $H_0$ is held guilty until proven innocent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54003d97",
   "metadata": {},
   "source": [
    "## Pervasive Problem\n",
    "\n",
    "- We should never conclude there is 'no difference' or 'no association' just becase a _p_-value is larger than a threshold such as 0.05 or, equivalently, because a confidence interval includes zero\n",
    "- We should also not conclude that two studies conflict because one had a statistically significant result and the other did not\n",
    "- These errors waste research efforts and misinform policy decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0934037",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "- Consider a series of analyses of unintended effects of anti-inflammatory drugs\n",
    "- Because their results were statistically non-significant, one set of researchers concluded that exposure to the drugs was \"not associated\" with new-onset atrial fibrillation (the most common disturbance to heart rhythm)\n",
    "- Argued that the results stood in contrast to those from an earlier study with a statistically significant outcome\n",
    "- The researchers describing their statistically non-significant results found a risk ratio of 1.2 (that is, a 20% greater risk in exposed patients relative to unexposed ones)\n",
    "- They also found a 95% confidence interval that spanned everything from a trifling risk decrease of 3% to a considerable risk increase of 48% (_p_ = 0.091)\n",
    "- The researchers from the earlier, statistically significant, study found the exact same risk ratio of 1.2\n",
    "- That study was simply more precise, with an interval spanning from 9% to 33% greater risk (_p_ = 0.0003)\n",
    "- Ludicrous to conclude that the statistically non-significant results showed \"no association\"\n",
    "- Interval estimate included serious risk increases\n",
    "- Equally absurd to claim these results were in contrast with the earlier results showing an identical observed effect\n",
    "- Reliance on thresholds of statistical significance can mislead us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8562a21",
   "metadata": {},
   "source": [
    "## The Insignificance of Null Hypothesis Significance Testing\n",
    "\n",
    "- Context: This article written 2 decades ago\n",
    "- Led in the social sciences by psychology, many are challenging the basic tenets of the way that nearly all social scientists are trained to develop and test empirical hypotheses\n",
    "- \"Strangle-hold\" (Rozenboom 1960)\n",
    "- \"Deeply flawed or else ill-used by researchers\" (Serlin and Lapsley 1993)\n",
    "- \"A terrible mistake, basically unsound, poor scientific strategy, and one of the worst things that ever happened in the history of psychology\" (Meehl 1978)\n",
    "- \"An instance of the kind of mindlessness in the conduct of research\" (Bakan 1960)\n",
    "- \"Badly misused for a long time (Cohen 1994)\n",
    "- \"Systematically retarded the growth of cumulative knowledge\" (Schmidt 1996)\n",
    "- \"The significance test as it is currently used in the social sciences just does not work\" (Hunter 1997)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e324fda",
   "metadata": {},
   "source": [
    "## Pervasiveness\n",
    "\n",
    "- These and similar errors are widespread\n",
    "- Surveys of hundreds of articles have found that statistically non-significant results are interpreted as indicating 'no difference' or 'no effect' in around half\n",
    "- In 2016, the American Statistical Association released a statement in _The American Statistician_ warning against the misuse of statistical significance and _p_-values\n",
    "- A special issue presents more than 40 papers on 'Statistical inference in the 21st century: a world beyond _p_ < 0.05', cautioning \"don't say 'statistically significant'\"\n",
    "- The authors call for the entire concept of statistical significance to be abandoned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a3c99f",
   "metadata": {},
   "source": [
    "## Receptivitiy\n",
    "\n",
    "- Authors invited others to read a draft of this comment and sign their names if they concurred with the message\n",
    "- 250 did so within the first 24 hours\n",
    "- A week later, more than 800 signatories — all checked for an academic affiliation or other indication of present or past work in a field that depends on statistical modelling\n",
    "- More than 50 countries and across all continents except Antarctica\n",
    "- One advocate called it a \"surgical strike against thoughtless testing of statistical significance\" and \"an opportunity to register your voice in favour of better scientific practices\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993e722",
   "metadata": {},
   "source": [
    "## Recomendations\n",
    "\n",
    "- Use **confidence intervals**; more informative\n",
    "- **Bayesian analysis**; calculate $p(\\theta|D,H_0)$\n",
    "- **Meta-analysis**: Offers attractive proposition that the accumulation of knowledge on some research question can be compared and combined in a single procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9a51d7",
   "metadata": {},
   "source": [
    "## Discussion Questions\n",
    "\n",
    "- This discussion is not new; why have we been unable to change practices?\n",
    "- Should there be a decision criteria; what would it be?\n",
    "- Should we care more about _p_-values or magnitudes?\n",
    "- Why is the null hypothesis significance test pervasive?\n",
    "- Have you seen a study that might speak to these issues?\n",
    "- Are there any alternatives not mentioned that you can think of?\n",
    "    - **Leave-one-out**, **Cross-validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33897fe9",
   "metadata": {},
   "source": [
    "## Pre-registration\n",
    "\n",
    "- The pre-registration of studies and a commitment to publish all results of all analyses can do much to mitigate these issues\n",
    "- Even results from pre-registered studies can be biased by decisions invariably left open in the analysis plan\n",
    "- This occurs even with the best of intentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03963b33",
   "metadata": {},
   "source": [
    "## Avoiding Dichotomous Engagement\n",
    "\n",
    "- All statistics, including _p_-values and confidence intervals, naturally vary from study to study, and often do so to a surprising degree\n",
    "- Random variation alone can easily lead to large disparities in _p_-values, far beyond falling just to either side of the e0.05 threshold\n",
    "- Even if researchers ...\n",
    "- Whether a _p_-value is small or large, caution is warranted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f2dd1",
   "metadata": {},
   "source": [
    "## Uncertainty\n",
    "\n",
    "- We must learn to embrace uncertainty\n",
    "- One practical way to do so is to rename confidence intervals as '**compatilibity intervals**' and interpret them in a way that **avoids overconfidence**\n",
    "- Recommend that authors describe the practical implications of all values inside the interval, especially the **observed effect** (or **point estimate**) and the **limits**\n",
    "- Remember that all values between the interval's limits are reasonably compatible with the data, given the statistical assumptions used to compute the interval\n",
    "- Singling out one particular value (such as the null value) in the interval as 'shown' makes no sense\n",
    "- An interval that contains the null value will often also contain non-null values of high practical importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba8a97",
   "metadata": {},
   "source": [
    "## Compatibility Intervals\n",
    "\n",
    "- Just because the interval gives the values most compatible with the data, given the assumptions, it doesn't mean values outside it are incompatible; they are just less compatible\n",
    "- Values just outside the interval do not differ substantively from those just inside the interval\n",
    "- It is thus wrong to claim that an interval shows all possible values\n",
    "- Not all values inside are equally compatible with the data, given the assumptions\n",
    "- The **point estimate** is the most compatible, and values near it are more compatible than those near the limits\n",
    "- Discuss the point estimate, even when they have a large _p_-value or a wide interval, as well as discussing the limits of that interval\n",
    "- The authors above could have written: 'Like a previous study, our results suggest a 20% increase in risk of new-onset atrial fibrillation in patients given the anti-inflammatory drugs. Nonetheless, a risk difference ranging from a 3% decrease, a small negative association, to a 48% increase, a substantial positive association, is also reasonably compatible with our data, given our assumptions.'\n",
    "- Interpreting the **point estimate**, while acknowledging its uncertainty, will keep you from making false declarations of 'no difference,' and from making overconfident claims\n",
    "- Like the 0.05 threshold from which it came, the default 95% used to compute intervals is itself an arbitrary convention\n",
    "- It is based on the false idea that there is a 95% chance that the computed interval itself contains the true value, coupled with the vague feeling that this is a basis for a confident decision\n",
    "- Interval estimates can perpetuate the problems of statistical significance when the dichotomization they impose is treated as a scientific standard\n",
    "- Be humble: **compatibility assessments** hinge on the correctness of the statistical assumptions used to compute the interval\n",
    "- In practice, these assumptions are at best subject to considerable **uncertainty**\n",
    "- Make these assumptions as clear as possible and test the ones you can, for example by plotting your data and by fitting alternative models, and then reporting all results\n",
    "- Whatever the statistics show, it is fine to suggest reasons for your results, but discuss a range of potential explanations, not just favoured ones\n",
    "- Inferences should be scientific, and that goes far beyond the merely statistical\n",
    "- Factors such as background evidence, study design, data quality and understanding of underlying mechanisms are often more important than statistical measures such as _p_-values or intervals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
